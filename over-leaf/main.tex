\typeout{Optical Coherence Tomography(OCT) based Retinal Fluid
Segmentation using Deep Learning Techniques}

% This is the instructions for authors for ACRA.
\documentclass{article}
\usepackage{acra}
\usepackage{titling}

% Reduce space between title and abstract
\setlength{\droptitle}{-4em}  % Adjust this value based on your preference

% Reduce space between abstract heading and body
\usepackage{etoolbox}
\patchcmd{\abstract}{\addvspace{10pt}}{\vspace{0pt}}{}{}
% The file acra.sty is the style file for ACRA. 
% The file named.sty contains macros for named citations as produced 
% by named.bst.

% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation. 

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Automated Generation of Executive Summaries of Online Meeting \\
using Natural Language Processing Techniques}

\author{
    Banda Sujith Kumar, Mohd Ramzan Shareef, Mohammed Arbaz \\
    Department of Information Technology \\
    Chaitanya Bharathi Institute of Technology \\
    Hyderabad, Telangana, India – 500075 \\
}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}

\begin{document}

\maketitle
\begin{abstract}
\textbf{\textit{
Meetings play a critical role in business decision-making, but manually capturing and summarizing discussions is time-consuming and prone to errors. This project introduces an automated system that leverages Natural Language Processing (NLP) to generate concise and actionable summaries from meeting transcripts. While previous research has focused on manual or platform-specific solutions, our approach processes transcripts from multiple online meeting platforms, integrating both extractive and abstractive summarization techniques. We utilize TF-IDF and TextRank for extracting key information, alongside advanced transformer models such as BERT for generating coherent summaries. Additionally, Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are incorporated to identify crucial details, including decisions made and responsibilities assigned. By automating the summarization process, our system improves meeting efficiency and accuracy. The system's performance will be evaluated using ROUGE scores and stakeholder feedback to ensure practical, high-quality summaries.
}}

\textbf{Keywords}: Natural Language Processing, Summarization, TF-IDF, TextRank, BERT, NER, ROUGE Scores
\end{abstract}

\section{Introduction}

The retina is a delicate layer of tissue at the back of the eye that plays a vital role in our ability to see. When conditions like Choroidal neovascularizatio(CNV) or age-related macular degeneration occur, they can cause fluid to accumulate, leading to the formation of retinal cysts. This not only disrupts vision but can also profoundly impact a person's quality of life. Detecting these issues early is crucial, as timely intervention can help preserve vision and improve outcomes for patients.

Traditionally, eye care professionals have relied on fundus photography to diagnose retinal disorders. However, this method has its limitations. It often requires trained specialists to analyze the images, which can be a slow and cumbersome process. The growing amount of imaging data in clinics adds to this challenge, making it difficult to keep up with patient needs.

Fortunately, optical coherence tomography (OCT) offers a more detailed view of the retina. This non-invasive imaging technique provides high-resolution, cross-sectional images that reveal the intricate layers of the retina. Unlike fundus photography, OCT allows for a clearer visualization of subtle changes that can signal the onset of retinal diseases. This enhanced clarity not only aids in earlier diagnosis but also helps doctors monitor changes over time, allowing for more effective treatment strategies.

Despite the advantages of OCT, analyzing these images can still be a daunting task. Manual interpretation is time-consuming and requires specialized knowledge, creating a bottleneck in patient care. This is where automation comes into play. While much of the existing research has focused on analyzing fundus images, we believe that the unique characteristics of OCT images present an exciting opportunity to improve the detection and segmentation of retinal cysts.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth,height=3.5cm,keepaspectratio]{images/oct.png}
    \caption{Different Retinal Fluid Conditions}
    \label{Retinal Fluid Diseases}
\end{figure}

In our study, we aim to leverage OCT imaging for the precise detection of retinal cysts. Building on foundational work that utilized the UNet architecture for image segmentation, we plan to enhance this approach by incorporating additional models, such as VGGNet, along with other deep learning techniques. By refining these algorithms, we hope to achieve better accuracy in identifying cysts, ultimately leading to more efficient diagnoses.

\newpage

The potential impact of an automated system for analyzing OCT images is significant. By reducing the reliance on manual interpretation, we can streamline workflows in ophthalmology clinics, enabling faster and more accurate diagnoses. Our goal is to enhance patient care by ensuring that retinal disorders are detected early, allowing for timely and effective treatment. In doing so, we hope to make a meaningful difference in the lives of those affected by retinal diseases.


\section{Methodology}






For model training, four distinct architectures were employed: Fully Convolutional Networks (FCN), U-Net, Seg-Net, and Deeplabv3+. Each architecture was trained using both 2D and 2.5D inputs, with three variations per model utilizing different hyperparameters, optimizers, and learning rates. Data augmentation techniques, including random rotation, mirroring, and translation, were implemented to bolster the models' generalization capabilities. The performance of each network was evaluated using the dice similarity coefficient (DSC), indicating that models trained on 2.5D inputs typically outperformed those based solely on 2D inputs. Furthermore, the researchers created ensembles of models that combined both input types, employing majority voting to enhance segmentation accuracy. \cite{alsaih2021retinal}.


 Loza Bekalo's work(2018) consists of two main phases: prior information modeling and retinal layer segmentation. In the first phase, a prior information model calculates the mean and variance of distance smoothness constraints from the layers of normal eyes, utilizing a graph-based approach to capture natural variations between retinal layers, crucial for detecting abnormalities. For segmenting NRD-associated subretinal fluid, a graph cut technique is employed, integrating regional and neighborhood information to isolate areas with uniform intensity. K-means clustering is applied to each B-scan to automatically identify seed points for the graph cut, categorizing pixels into clusters based on reflectivity levels, which inform the seeds for the fluid and retinal region. In the second phase, a graph search method segments the 11 retinal surfaces, using the prior information model to confine search areas and ensure accurate delineation, even in the presence of subretinal fluid. The cost function for each voxel is derived from gradient information from the B-scans, enhancing layer boundaries. The search process is optimized by integrating pixel extraction constraints and implementing a "divide and merge" strategy to process B-scans in smaller batches while maintaining the continuity of the retinal layers\cite{bekalo2021automated}.

The segmentation models are trained on the RETOUCH dataset, which comprises 70 training volumes and 42 testing volumes, with expert manual annotations ensuring accuracy. Evaluation metrics, including Dice Score (DS), Absolute Volume Difference (AVD), and Area Under the Curve (AUC), are utilized to assess the models' performance in segmentation and detection. The study reveals the strengths and limitations of various models; notably, while the SAMedOCT model demonstrates promising results post fine-tuning, the specialized nnUNet and its variant nnUNet\_RASPP consistently outperform other models in both segmentation and generalization tasks. The nnUNet\_RASPP incorporates residual connections and atrous spatial pyramid pooling (ASPP) to effectively capture global contextual features, addressing data variability challenges from different devices. Predictions are evaluated in a blinded manner to ensure unbiased assessment, with results showing that nnUNet\_RASPP achieves the highest mean Dice Score and the lowest Absolute Volume Difference, confirming its superior generalization across diverse OCT datasets. The study concludes that, despite the potential of large foundation models like SAMedOCT, specialized models such as nnUNet\_RASPP exhibit a distinct advantage in specific medical image segmentation tasks.\cite{ndipeno2021performance}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth,height=3.5cm,keepaspectratio]{images/layers.png}
    \caption{ 11 surfaces (Surf) from The Iowa Reference Algorithms [3] overlaid on
 the B-scan. The 11 surfaces delineate ten retinal layers, namely, the Nerve
 Fiber Layer (NFL), the Ganglion Cell Layer (GCL), the Inner Plexiform Layer
 (IPL), the Inner Nuclear Layer (INL), the Outer Plexiform Layer (OPL),
 the Outer Nuclear Layer (ONL), the Inner Segment (IS), and the Outer
 Segment (OS), Outer Photoreceptor (OPR), Retinal Pigment
 Epithelium (RPE).}
    \label{Retinal Fluid Layers}
\end{figure}

The authors propose the Structure-guided Cross-Attention Network (SCAN) to enhance domain adaptation for OCT fluid segmentation by addressing the domain gap between images captured from different devices. By leveraging stable retinal layer structures, which remain consistent across domains, SCAN improves segmentation performance despite the variability of fluid regions. The framework employs a multi-task approach, enabling the model to jointly predict retinal layer structures and segment fluid areas, utilizing a cross-attention module to assess correlations between layer-specific and \newpage fluid-specific features. Additionally, adversarial learning is integrated through a domain discriminator that distinguishes between source and target segmentation maps, while an adaptation difficulty map, based on discrepancies in predicted retinal layer maps, guides the model to focus on more challenging regions during training. Extensive experiments on the RETOUCH dataset demonstrate that SCAN significantly outperforms existing state-of-the-art methods for cross-domain OCT fluid segmentation, highlighting its effectiveness in bridging domain gaps.\cite{he2021structure}.

The methodology outlined in the RETOUCH challenge paper focuses on evaluating automated methods for detecting and segmenting retinal fluids in Optical Coherence Tomography (OCT) images. The challenge aimed to establish a standardized benchmark for assessing the accuracy of algorithms in detecting three key types of retinal fluids: Intraretinal Fluid (IRF), Subretinal Fluid (SRF), and Pigment Epithelial Detachment (PED), which are crucial biomarkers in conditions like Age-related Macular Degeneration (AMD) and Retinal Vein Occlusion (RVO). The dataset consists of 112 OCT volumes from various devices, all annotated by expert graders, and the challenge is divided into two main tasks: fluid detection and fluid segmentation. Performance is evaluated using metrics such as the Dice Similarity Coefficient (DSC) and Absolute Volume Difference (AVD). Participating teams developed deep learning approaches, predominantly utilizing U-Net or fully convolutional network (FCN) architectures. The methodology also addresses multi-device data variability and multi-center grading agreement to gauge the robustness of the automated methods, incorporating data augmentation and pre-processing techniques like histogram matching to mitigate variability between scans from different devices. \cite{bogunovic2021retouch}.


B.N Anoop's work (2023) employs a deep ensemble learning-based convolutional neural network (CNN) architecture for multiclass retinal fluid segmentation in OCT images, focusing on three types of fluids: intraretinal fluid (IRF), subretinal fluid (SRF), and pigment epithelial detachment (PED), which are crucial indicators in retinal diseases like macular edema and diabetic retinopathy. The methodology involves training three distinct CNN models, one for each fluid type, which are combined into an ensemble architecture that uses majority voting to enhance segmentation performance. Evaluated with the publicly available RETOUCH dataset, this approach showed a 1.8\% improvement in segmentation accuracy over state-of-the-art methods. For each fluid type, customized CNN architectures were utilized: a U-Net model for IRF segmentation enhanced with a relative layer distance algorithm to improve spatial context; a model for SRF segmentation that incorporated structured dropout blocks to reduce overfitting; and a PED segmentation model that employed data augmentation techniques to enhance performance. The segmentation pipeline also included preprocessing steps like cropping, denoising, and contrast enhancement to ensure high-quality OCT scans before inputting them into the CNN models. \cite{rahil2021deep}.


The methodology consists of a two-stage approach for segmenting neurosensory retinal detachment (NRD) associated with subretinal fluid in spectral domain optical coherence tomography (SD-OCT) images, guided by Enface fundus imaging. In the first stage, the Enface fundus image is segmented using a thickness map to identify fluid-related abnormalities that typically exhibit diffuse boundaries, thereby locating potential fluid accumulation with enhanced accuracy through probabilistic insights based on retinal thickness. In the second stage, the spatial extent of the fluid region is refined using a fuzzy level set method with a spatial smoothness constraint, integrating intensity and morphological information from both the Enface fundus image and the thickness map for precise segmentation. This fully automatic method eliminates the need for manual initialization, distinguishing it from previous semi-supervised approaches, and restricts the segmentation to relevant regions of interest, improving accuracy and reducing the risk of false positives. \cite{wu2021automatic}.

The methodology of the RetiFluidNet paper introduces a self-adaptive and multi-attention deep convolutional network designed for segmenting retinal fluids in OCT images. Its core innovation integrates several key components: a self-adaptive dual-attention (SDA) mechanism, attention-based skip connections (SASC), and a multi-scale deep self-supervision learning (DSL) framework. The SDA module captures deformation-aware representations by emphasizing both spatial and channel features, allowing the model to adapt dynamically to various fluid region sizes and shapes. The SASC paths enhance contextual information transfer between encoder and decoder layers, improving segmentation accuracy by reducing false positives and enhancing edge detection. The DSL scheme employs a hierarchical loss function that combines weighted dice overlap and connectivity-based losses across multiple scales, optimizing the model for texture-specific features and edge preservation. RetiFluidNet is trained and validated on three publicly available datasets—RETOUCH, OPTIMA, and DUKE—and benchmarked against several baseline methods. Extensive experiments, including ablation studies, demonstrate that RetiFluidNet significantly outperforms state-of-the-art algorithms, particularly in adapting to noisy, blurred, and varied OCT fluid regions. \cite{rasti2021retifluidnet}.

\newpage
\clearpage

% Clear any floating elements and start a new page

\renewcommand{\arraystretch}{1.5} % Increase row height for better readability

\begin{table}[htp]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|p{4cm}|p{4cm}|p{4cm}|c|}
\hline
\textbf{S.No} & \textbf{Paper Title} & \textbf{Advantages} & \textbf{Disadvantages} & \textbf{Publish Year} \\ \hline

1 & Automatic Meeting Minutes Generation Using Natural Language Processing & Automates meeting summarization by extracting key points, summarizing discussions, and identifying action items with BART and T5 models. Adaptable to both transcript and audio inputs, it can summarize complex meeting discussions effectively. & TLimited by dataset diversity, which affects its performance across varied domains or industries. High processing demands for NLP tasks may restrict real-time application, making it challenging to implement in fast-paced or low-resource environments. & August 18, 2020 \\ \hline

2 & Automation of Text Summarization Using Hugging Face Natural Language Processing & Employs high-performing transformer models like BERT and GPT for extractive and abstractive summarization, with strong ROUGE scores and adaptability to large datasets. Hugging Face tools enhance scalability and make it suitable for diverse applications, like summarizing news and research articles. & Requires substantial computational power, limiting its practicality on low-end devices. The English-focused CNN/Daily Mail dataset reduces its generalizability to other languages and content types without additional fine-tuning, impacting broader usability. & January 21, 2019 \\ \hline

3 & Minutes of Meeting Generation for Online Meetings Using NLP and ML Techniques & Uses a multi-model setup (PEGASUS, BART, LED) for meeting summarization with effective speaker diarization, capturing timestamps and speaker identities to ensure accurate transcripts. The model’s flexibility allows it to handle different audio formats and complex multi-speaker environments. & Diarization accuracy varies (20-35\% error), especially in noisy settings, potentially impacting transcription reliability. The combination of multiple models demands significant computational resources, making it less suited for real-time processing in high-volume settings. & February 26, 2024 \\ \hline

4 & Natural Language Processing Based Automated Text Summarization and Translation & Provides a secure, professional-grade GUI for text summarization and translation, achieving high accuracy (91-95\%) and integrating face recognition for user authentication. Designed for a smooth user experience, it includes advanced error handling for various document types. & High computational costs due to security features like face recognition, which require specific libraries such as OpenCV. The system’s dependency on these libraries limits its cross-platform compatibility and may introduce a learning curve for non-technical users. & December 14, 2022 \\ \hline

\end{tabular}
\end{table}

\newpage
\clearpage

\begin{table}[htp]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|p{4cm}|p{4cm}|p{4cm}|c|}
\hline
\textbf{S.No} & \textbf{Paper Title} & \textbf{Advantages} & \textbf{Disadvantages} & \textbf{Publish Year} \\ \hline



5 &Enhancing Text Summarization through Parallelization: A TF-IDF Algorithm Approach & Parallelization of TF-IDF summarization optimizes speed and scalability, making it ideal for processing large text datasets efficiently. The algorithm’s design allows for rapid extraction of high-relevance sentences, making it effective in scenarios needing quick summarization without sacrificing accuracy. & Requires substantial computational resources, especially when used on extensive datasets or in distributed environments, which may limit applicability in resource-constrained settings. The extractive focus also restricts its adaptability for nuanced, abstractive summarization tasks where context-building is essential. & February 26, 2019 \\ \hline

6 & An Approach for Audio/Text Summary Generation from Webinars/Online Meetings & Effectively converts video content into both text and audio summaries, allowing for easy reference to key points without reviewing full recordings. It includes multilingual translation, making the system versatile for diverse audiences, which is especially valuable in global corporate and educational settings. & The lack of a standardized dataset means evaluations rely on manual assessments, which may introduce inconsistencies. Additionally, without specific datasets, performance across varied domains or languages may require significant adaptation and extra validation work. & February 19, 2023 \\ \hline

7 & Comparative Analysis of Different Text Summarization Techniques Using Enhanced Tokenization & The paper’s focus on tokenization methods and summarization for Bangla offers a unique contribution, optimizing handling of non-standard language data. Enhanced tokenization improves the model’s ability to capture and process complex linguistic features in non-standardized text, helping improve summarization outcomes in diverse language contexts. & Primarily tailored for Bangla, it may not generalize effectively to other languages or datasets without customization. The need for extensive preprocessing due to the intricacies of non-standard languages could introduce higher computational and time costs, impacting scalability. & February 19, 2023 \\ \hline

8 & Harnessing Deep Learning for Effective Extractive Text Summarization: A Comparative Study & Provides a robust comparison of deep learning models, like T5, for summarization tasks with high ROUGE scores, enabling researchers to select high-performing models tailored to specific fields such as law, academia, or media. It highlights the strengths and weaknesses of various models, aiding in the targeted development of specialized summarization systems. & Significant computational demand from deep learning models limits accessibility for smaller or lower-power environments. Additionally, the study is focused on extractive summarization, so it doesn’t address generative tasks, which may limit its adaptability for tasks requiring contextually enriched summaries. & February 19, 2023 \\ \hline

\end{tabular}
\end{table}

\newpage
\clearpage

\begin{table}[htp]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|p{4cm}|p{4cm}|p{4cm}|c|}
\hline
\textbf{S.No} & \textbf{Paper Title} & \textbf{Advantages} & \textbf{Disadvantages} & \textbf{Publish Year} \\ \hline

9 & Comparative Study on Extractive Summarization Using Sentence Ranking Algorithm and Text Ranking Algorithm & Demonstrates practical, accurate summarization by leveraging sentence-ranking and TextRank algorithms, offering structured methods that enhance content relevance and readability in summaries. The approach provides an efficient ranking model, making it easy to adapt for various content types that require concise extraction of main ideas. & Heavy reliance on frequency and position features may lead to redundancy and fail to capture nuanced context. It lacks flexibility for abstractive summarization, so content that needs paraphrasing or deeper interpretation may not perform well under this approach, reducing utility in complex datasets. & April 18, 2017 \\ \hline

10 & Text Summarization Based Named Entity Recognition for Certain Application Using BERT & RLeverages BERT for Named Entity Recognition (NER) to provide accurate, contextually aware summaries. Incorporates deep learning techniques that enhance performance, with high validation accuracy observed after fine-tuning. & High computational demand for BERT, limiting accessibility for lower-resource systems. Specific to NER tasks, which may restrict general application across other NLP tasks without customization. & December 14, 2022 \\ \hline

11 & Text Summarization based on Feature Extraction using GloVe and B-GRU & Combines GloVe embeddings with Bi-GRU, capturing semantic relationships between words for richer, more relevant summaries. Employs feature extraction with attention layers, achieving strong results on PubMed and arXiv datasets. & Complex architecture with GloVe and Bi-GRU increases computational load. Performance may vary outside the scientific domain, requiring further testing on diverse datasets for broader applicability. & December 14, 2022 \\ \hline

12 & A Ranking based Language Model for Automatic Extractive Text Summarization & Implements a ranking-based language model for effective sentence selection, achieving high ROUGE scores for summarizing news datasets. Efficiently handles large datasets like CNN and BBC News, producing summaries that maintain key information. & Dependent on n-gram models, which may miss out on deeper semantic meaning. Limited adaptability for abstractive summarization tasks, as it focuses primarily on extractive methods. & December 14, 2022 \\ \hline

\end{tabular}
\end{table}

\newpage
\clearpage

\begin{table}[htp]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|p{4cm}|p{4cm}|p{4cm}|c|}
\hline
\textbf{S.No} & \textbf{Paper Title} & \textbf{Advantages} & \textbf{Disadvantages} & \textbf{Publish Year} \\ \hline

13 & A Text Structure-based Extractive and Abstractive Summarization Method & Uses a hybrid approach by combining extractive and abstractive methods, balancing coherence with conciseness. Clusters text by thematic structure, allowing tailored summarization strategies for different sections of the text. & Requires fine-tuning for optimal segmentation and clustering, which may be computationally intensive. Focuses on structured text, so may be less effective for unstructured or highly variable formats. & April 18, 2017 \\ \hline

14 & Implementation of Novel Test Rank Algorithm for Effective Text Summarization & Introduces an innovative Test Rank algorithm for effective text summarization, efficiently ranking sentences by relevance. Suitable for applications where quick access to key points is essential, as it improves text coherence through structured ranking. & Relies heavily on sentence similarity, which can lead to redundancy and may not capture nuanced context effectively. Limited evaluation on diverse datasets, which may impact generalizability across varied document types. & December 14, 2022 \\ \hline


\end{tabular}
\caption{Summary of Literature Survey on Executive Summaries of Online Meeting using NLP }
\label{table:literature_survey}
\end{table}

% Clear floating tables or figures before continuing to the next section
\clearpage

\section{Conclusion}

The rising prevalence of retinal disorders has created a growing demand for the development of more sophisticated and efficient diagnostic tools, particularly those that can address the limitations of manual Optical Coherence Tomography (OCT) image analysis. As retinal diseases like diabetic macular edema and age-related macular degeneration become more common, early detection and accurate diagnosis are critical in managing these conditions and preventing severe vision loss. Traditional approaches to retinal imaging, such as fundus photography, have been widely used in clinical settings. However, while fundus images provide a broad view of the retina, they lack the depth and detail required to visualize subtle changes or abnormalities within the retina’s layers, which are crucial for diagnosing conditions that involve fluid accumulation or structural alterations. OCT imaging, with its ability to produce high-resolution cross-sectional views of the retina, has emerged as an invaluable tool for diagnosing and monitoring these conditions. It allows clinicians to detect changes within the retinal layers that are often invisible in traditional imaging techniques, making it a more powerful solution for identifying abnormalities like retinal cysts and other forms of fluid retention.

Despite the potential of OCT imaging, its effectiveness is hindered by the time-consuming and labor-intensive nature of manual image analysis, which is prone to human error and variability. To fully realize the benefits of OCT technology, there is a pressing need for the integration of advanced automated systems that can accurately and efficiently analyze these images. Deep learning techniques, particularly in the field of medical image analysis, offer a promising solution by automating the detection and segmentation of retinal abnormalities, such as cysts and fluid accumulation, in OCT images. By harnessing the power of artificial intelligence, these systems can significantly improve the speed and accuracy of diagnoses, allowing for earlier detection and more targeted treatments. This not only enhances patient outcomes but also reduces the burden on healthcare professionals, who are often faced with the challenge of manually analyzing large volumes of OCT images. In the long run, the implementation of deep learning-driven diagnostic tools will streamline the diagnostic process, improve clinical decision-making, and contribute to more efficient management of retinal disorders, ultimately benefiting both patients and the healthcare system.

%% This section was initially prepared using BibTeX. The .bbl file was
%% placed here later.
%\bibliography{publications}
%\bibliographystyle{named}




\newpage

\begin{thebibliography}{}

\bibitem{alsaih2021retinal}
Khaled Alsaih, Mohd Zuki Yusoff, Ibrahima Faye, Tong Boon Tang, and Fabrice Meriaudeau,
\newblock “Retinal Fluid Segmentation Using Ensembled 2-Dimensionally and 2.5-Dimensionally Deep Learning Networks,”
\newblock \emph{IEEE}, 2021.

\bibitem{bekalo2021automated}
Loza Bekalo, Sijie Niu, Xiaojun He, Ping Li, Idowu Paul Okuwobi, Chenchen Yu, Wen Fan, Songtao Yuan, and Qiang Chen,
\newblock “Automated 3-D Retinal Layer Segmentation From SD-OCT Images With Neurosensory Retinal Detachment,”
\newblock \emph{IEEE}, 2021.

\bibitem{ndipeno2021performance}
Nchongmaje Ndipeno, Alina Miron, and Yongmin Li,
\newblock “Performance Evaluation of Retinal OCT Fluid Segmentation, Detection, and Generalization Over Variations of Data Sources,”
\newblock \emph{IEEE}, 2021.

\bibitem{he2021structure}
Xingxin He, Zhun Zhong, Leyuan Fang, Min He, and Nicu Sebe,
\newblock “Structure-Guided Cross-Attention Network for Cross-Domain OCT Fluid Segmentation,”
\newblock \emph{IEEE}, 2021.


\bibitem{bogunovic2021retouch}
Hrvoje Bogunović, Freerk Venhuizen, Sophie Klimscha, Stefanos Apostolopoulos, Alireza Bab-Hadiashar, Ulas Bagci, Mirza Faisal Beg, Loza Bekalo, Qiang Chen, Carlos Ciller, Karthik Gopinath, Amirali K. Gostar, Kiwan Jeon, Zexuan Ji, Sung Ho Kang, Dara D. Koozekanani, Donghuan Lu, Dustin Morley, Keshab K. Parhi, Hyoung Suk Park, Abdolreza Rashno, Marinko Sarunic, Saad Shaikh, Jayanthi Sivaswamy, Ruwan Tennakoon, Shivin Yadav, Sandro De Zanet, Sebastian M. Waldstein, Bianca S. Gerendas, Caroline Klaver, Clara I. Sánchez, and Ursula Schmidt-Erfurth,
\newblock “RETOUCH: The Retinal OCT Fluid Detection and Segmentation Benchmark and Challenge,”
\newblock \emph{IEEE}, 2021.


\bibitem{rahil2021deep}
Mohammad Rahil, B. N. Anoop, G. N. Girish, Abhishek R. Kothari, Shashidhar G. Koolagudi, and Jeny Rajan,
\newblock “A Deep Ensemble Learning-Based CNN Architecture for Multiclass Retinal Fluid Segmentation in OCT Images,”
\newblock \emph{IEEE}, 2021.

\bibitem{wu2021automatic}
Menglin Wu, Qiang Chen, XiaoJun He, Ping Li, Wen Fan, SongTao Yuan, and Hyunjin Park,
\newblock “Automatic Subretinal Fluid Segmentation of Retinal SD-OCT Images With Neurosensory Retinal Detachment Guided by Enface Fundus Imaging,”
\newblock \emph{IEEE}, 2021.

\bibitem{rasti2021retifluidnet}
Reza Rasti, Armin Biglari, Mohammad Rezapourian, Ziyun Yang, and Sina Farsiu,
\newblock “RetiFluidNet: A Self-Adaptive and Multi-Attention Deep Convolutional Network for Retinal OCT Fluid Segmentation,”
\newblock \emph{IEEE}, 2021.


\end{thebibliography}
\clearpage

\end{document}